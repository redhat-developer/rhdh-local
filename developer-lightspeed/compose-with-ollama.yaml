services:
  install-dynamic-plugins:
    volumes:
      - ./developer-lightspeed/configs:/opt/app-root/src/developer-lightspeed/configs:Z
  rhdh:
    volumes:
      - ./developer-lightspeed/configs:/opt/app-root/src/developer-lightspeed/configs:Z
  rag-init:
    image: 'quay.io/redhat-ai-dev/rag-content:release-1.7-lcs'
    container_name: rag-init
    user: "0:0"
    volumes:
      - rag_embeddings:/data/embeddings_model
      - rag_vector_db:/data/vector_db
    entrypoint: [ "sh", "-c" ]
    command: >
      "set -e; echo 'Copying RAG data...' && \
      mkdir -p /data/vector_db /data/embeddings_model && \
      cp -r /rag/vector_db/* /data/vector_db/ && \
      cp -r /rag/embeddings_model/* /data/embeddings_model/ && \
      chown -R 1001:0 /data/vector_db /data/embeddings_model || true && \
      chmod -R a+rwX /data/vector_db /data/embeddings_model && \
      echo 'Copy complete.' && sleep 10"
    restart: "on-failure"
  ollama:
    image: docker.io/ollama/ollama:0.10.0-rc0
    container_name: ollama
    volumes:
      - ${OLLAMA_MODELS_PATH:-ollama_data}:/root/.ollama
    depends_on:
      rhdh:
        condition: service_started
    network_mode: "service:rhdh"
    env_file:
      - path: "./default.env"
        required: true
      - path: "./.env"
        required: false
    command: >
      "ollama serve & sleep 5 && ollama pull ${OLLAMA_MODEL:-llama3.2:1b} && touch /tmp/ready && wait"
    entrypoint: [ "sh", "-c" ]
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "test", "-f", "/tmp/ready" ]
      interval: 15s
      timeout: 5s
      retries: 5
  llama-stack:
    image: ${LLAMA_STACK_IMAGE:-quay.io/redhat-ai-dev/llama-stack:latest} # dclint disable-line service-image-require-explicit-tag
    container_name: llama-stack
    volumes:
      - ./developer-lightspeed/configs/extra-files/run-no-validation.yaml:/app-root/run.yaml:Z
      - rag_embeddings:/app-root/embeddings_model
      - rag_vector_db:/app-root/vector_db
    depends_on:
      rag-init:
        condition: service_completed_successfully
      ollama:
        condition: service_healthy
    env_file:
      - path: "./default.env"
        required: true
      - path: "./.env"
        required: false
    network_mode: "service:rhdh"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8321/v1/models || exit 1"]
      interval: 5s
      timeout: 5s
      retries: 5
      start_period: 10s
  lightspeed-core-service:
    image: ${LIGHTSPEED_CORE_IMAGE:-quay.io/lightspeed-core/lightspeed-stack:0.3.0} # dclint disable-line service-image-require-explicit-tag
    container_name: lightspeed-core-service
    depends_on:
      rhdh:
        condition: service_started
      ollama:
        condition: service_healthy
      llama-stack:
        condition: service_healthy
    volumes:
      - ./developer-lightspeed/configs/extra-files/lightspeed-core-service-config.yaml:/app-root/lightspeed-stack.yaml:Z
    env_file:
      - path: "./default.env"
        required: true
      - path: "./.env"
        required: false
    network_mode: "service:rhdh"
volumes:
  ollama_data:
  rag_embeddings:
  rag_vector_db:
