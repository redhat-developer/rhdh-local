version: '2'
image_name: llama-stack-no-question-validation

apis:
  - agents
  - datasetio
  - eval
  - inference
  - post_training
  - safety
  - scoring
  - telemetry
  - tool_runtime
  - vector_io
benchmarks: []
container_image: null
datasets: []
external_providers_dir: null
inference_store:
  db_path: .llama/distributions/ollama/inference_store.db
  type: sqlite
logging: null
metadata_store:
  db_path: .llama/distributions/ollama/registry.db
  namespace: null
  type: sqlite
providers:
  agents:
  - config:
      persistence_store:
        db_path: .llama/distributions/ollama/agents_store.db
        namespace: null
        type: sqlite
      responses_store:
        db_path: .llama/distributions/ollama/responses_store.db
        type: sqlite
    provider_id: meta-reference
    provider_type: inline::meta-reference
  datasetio:
  - config:
      kvstore:
        db_path: .llama/distributions/ollama/huggingface_datasetio.db
        namespace: null
        type: sqlite
    provider_id: huggingface
    provider_type: remote::huggingface
  - config:
      kvstore:
        db_path: .llama/distributions/ollama/localfs_datasetio.db
        namespace: null
        type: sqlite
    provider_id: localfs
    provider_type: inline::localfs
  eval:
  - config:
      kvstore:
        db_path: .llama/distributions/ollama/meta_reference_eval.db
        namespace: null
        type: sqlite
    provider_id: meta-reference
    provider_type: inline::meta-reference
  inference:
    - provider_id: ${env.ENABLE_VLLM:+vllm}
      provider_type: remote::vllm
      config:
        url: ${env.VLLM_URL:=http://localhost/v1}
        api_token: ${env.VLLM_API_KEY:=token}
        max_tokens: ${env.VLLM_MAX_TOKENS:=4096}
        tls_verify: ${env.VLLM_TLS_VERIFY:=true}
    - provider_id: ${env.ENABLE_OLLAMA:+ollama}
      provider_type: remote::vllm
      config:
        url: ${env.OLLAMA_URL:=http://localhost:11434/v1}
        api_token: ${env.OLLAMA_TOKEN:=token}
    - provider_id: ${env.ENABLE_OPENAI:+openai}
      provider_type: remote::openai
      config:
        api_key: ${env.OPENAI_API_KEY:=token}
    - provider_id: ${env.ENABLE_VERTEX_AI:+vertexai}
      provider_type: remote::vertexai
      config:
        project: ${env.VERTEX_AI_PROJECT:=}
        location: ${env.VERTEX_AI_LOCATION:=us-central1}
    - provider_id: sentence-transformers
      provider_type: inline::sentence-transformers
      config: {}
  post_training:
  - config:
      checkpoint_format: huggingface
      device: cpu
      distributed_backend: null
      dpo_output_dir: "."
    provider_id: huggingface
    provider_type: inline::huggingface
  safety: []
  scoring:
  - config: {}
    provider_id: basic
    provider_type: inline::basic
  - config: {}
    provider_id: llm-as-judge
    provider_type: inline::llm-as-judge
  - config:
      openai_api_key: '********'
    provider_id: braintrust
    provider_type: inline::braintrust
  telemetry:
  - config:
      service_name: 'lightspeed-stack-telemetry'
      sinks: sqlite
      sqlite_db_path: .llama/distributions/ollama/trace_store.db
    provider_id: meta-reference
    provider_type: inline::meta-reference
  tool_runtime:
  - provider_id: model-context-protocol
    provider_type: remote::model-context-protocol
    config: {}
  - provider_id: rag-runtime 
    provider_type: inline::rag-runtime
    config: {}
  vector_io:
  - config:
      kvstore:
        db_path: .llama/distributions/ollama/faiss_store.db
        namespace: null
        type: sqlite
    provider_id: faiss
    provider_type: inline::faiss
  - provider_id: rhdh-docs 
    provider_type: inline::faiss
    config:
      kvstore:
        type: sqlite
        namespace: null
        db_path: /app-root/vector_db/rhdh_product_docs/1.8/faiss_store.db
scoring_fns: []
server:
  auth: null
  host: null
  port: 8321
  quota: null
  tls_cafile: null
  tls_certfile: null
  tls_keyfile: null
shields: []
tool_groups:
- provider_id: rag-runtime
  toolgroup_id: builtin::rag
  description: "Only use for questions specifically about Red Hat Developer Hub (RHDH). Searches technical documentation for RHDH installation, discovery, configuration, release, upgrade, control access, integration, observability, and extending with plugins. Do not use for any other topic outside RHDH."
vector_dbs:
- embedding_dimension: 768
  embedding_model: /app-root/embeddings_model
  provider_id: rhdh-docs
  vector_db_id: rhdh-product-docs-1_8
models:
- model_id: sentence-transformers/all-mpnet-base-v2
  metadata:
      embedding_dimension: 768
  model_type: embedding
  provider_id: sentence-transformers
  provider_model_id: "/app-root/embeddings_model"
